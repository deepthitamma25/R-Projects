---
title: "Machine Learning Project"
---


**Your Name**: Deepthi Tamma
**Your G Number**: G01241465



```{r warning = FALSE, message = FALSE}
# Suppress dplyr summarise grouping warning messages
options(dplyr.summarise.inform = FALSE)

## Add R libraries here
install.packages("scales")
install.packages("tidymodels")
install.packages("kknn")
install.packages("ranger")
install.packages("vip")
install.packages("caret")
library(tidyverse)
library(tidymodels)
library("ranger")
library("vip")
library("kknn")
library("caret")
# Load the dataset
telecom_df <- read_rds(url('https://gmubusinessanalytics.netlify.app/data/telecom_df.rds'))

```



# Data Analysis

In this section, you must think of at least 5 relevant questions that explore the relationship between `canceled_service` and the other variables in the `telecom_df` data set. The goal of your analysis should be discovering which variables drive the differences between customers who do and do not cancel their service.

You must answer each question and provide supporting data summaries with either a summary data frame (using `dplyr`/`tidyr`) or a plot (using `ggplot`) or both.

In total, you must have a minimum of 3 plots (created with `ggplot`) and 3 summary data frames (created with `dplyr`) for the exploratory data analysis section. Among the plots you produce, you must have at least 3 different types (ex. box plot, bar chart, histogram, scatter plot, etc...)

See the [Data Analysis Project](https://gmubusinessanalytics.netlify.app/data-analysis-project.html) for an example of a question answered with a summary table and plot.

**Note**: To add an R code chunk to any section of your project, you can use the keyboard shortcut `Ctrl` + `Alt` + `i` or the `insert` button at the top of your R project template notebook file.



# Question 1


**Question**: Is there any relation between the amount of charge they pay and the type of contract they choose? 


**Answer**: Yes, it can be observed that the customers who tend to leave the company is due to amount i.e., monthly charges they’ve been charged to the type of contract they have enrolled in. From the plot, it can be observed that though the customers who have enrolled in the same type of contact, those customers who left the company have paid more monthly charges than those who stayed back. 


```{r}
by_charges<-telecom_df%>% group_by(canceled_service,contract)%>%
  summarise(no_customers=n(),
    avg_charges=mean(monthly_charges))
by_charges

ggplot(by_charges,aes(x=contract,y=avg_charges)) + geom_col() + 
  expand_limits(y = 0)+ facet_wrap(~canceled_service) +
   labs(title = 'Bar plot of Contract Vs Average Amount Charged ',
       x = 'Contract',
       y = 'Monthly Charges')


```



# Question 2


**Question**: Is there any relation between the Online security provided with the progress in number of months associated with the company?


**Answer**: Yes, the customers are terminating the service is due to the online security provided by the company over the progress of years. This means that most of the customers who have cancelled their service doesn’t have the online security even though many years progressed and hence due to insecurity, most of the costumers have terminated the service.


```{r}
ggplot(telecom_df, aes(x = months_with_company, fill = online_security)) + 
  geom_density(alpha = 0.6) + facet_wrap(~canceled_service, nrow = 2)+
   labs(title = 'Density Plot of Months with company Vs Online Security ',
       x = 'Online Security',
       y = 'Number of Months with company')


```


# Question 3


**Question**: Is there any relation between the Average Call duration with the number of months associated with the company?


**Answer**:Yes, the customer’s call duration in minutes also give information about the reason why the customers have terminated the service. From the plot, we can say that as the years progress, the average duration of call has been reduced gradually which means that the customers no longer are making calls and are not having communication through their cell which means that they no longer have to pay the charges and use the service which in turn is leading of customers to terminate the service.


```{r}
ggplot(telecom_df, aes(x = months_with_company, y = avg_call_mins)) + 
  geom_point() +
  facet_wrap(~ canceled_service , nrow = 2)+
  labs(title = 'Scatter Plot of Months with company Vs Average Call duration ',
       x = 'Number of Months with company',
       y = 'Average Call duration')


```



# Question 4


**Question**: Is there any relationship between the amount charged with the Online back up plan?


**Answer**: Yes, from the summary table below, we can see that the customers who have terminated the service paid more amount of charge for having the Online back up when compared to those who are still continuing the service with the Online backup. Also, the customers who left who don't have online backup are paying more amount than those who stayed back without online backup.


```{r}
telecom_df%>% group_by(canceled_service,online_backup)%>%
  summarise(no_customers=n(),
    avg_charges=mean(monthly_charges))



```



# Question 5


**Question**: Is there any relation between the monthly charges and the average duration of the calls?

**Answer**: yes, we see that there is a constant amount of money charged irrespective of the duration of their calls which means that they have been paying more money for the service they have used which is leading the customers to terminate the service


```{r}
telecom_df%>% group_by(canceled_service)%>%
  summarise(no_customers=n(),
            avg_mins=mean(avg_intl_mins),
            avg_charges=mean(monthly_charges))


```

From the Summary table below, we can say that those who pay by using the Electronic checks are mostly tending to terminate their service

```{r}
telecom_df%>% group_by(canceled_service,payment_method)%>%
  summarise(no_canceled_service=n())
```

From the summary table below, it can be observed that those customers whose internet service is fiber_optic and those whose contract is on monthly basis, tend to terminate their service with the Telecom company


```{r}
telecom_df%>% group_by(canceled_service,internet_service,contract)%>%
  summarise(no=n())


```

From the below summary table, it can be observed that most of the senior citizens tend to terminate their internet and the cellular service when compared to those of non-senior citizens


```{r}
telecom_df%>% group_by(canceled_service,senior_citizen)%>%
  summarise(no_customers=n(),
    avg_months=mean(months_with_company))

```

# Machine Learning


In this section of the project, you will fit **three classification algorithms** to predict the response variable,`canceled_service`. You should use all of the other variables in the `telecom_df` data as predictor variables for each model.

You must follow the machine learning steps below. 

The data splitting and feature engineering steps should only be done once so that your models are using the same data and feature engineering steps for training.

- Split the `telecom_df` data into a training and test set (remember to set your seed)
- Specify a feature engineering pipeline with the `recipes` package
    - You can include steps such as skewness transformation, dummy variable encoding or any other steps you find appropriate
- Specify a `parsnip` model object
    - You may choose from the following classification algorithms:
      - Logistic Regression
      - LDA
      - QDA
      - KNN
      - Decision Tree
      - Random Forest
- Package your recipe and model into a workflow
- Fit your workflow to the training data
    - If your model has hyperparameters:
      - Split the training data into 5 folds for 5-fold cross validation using `vfold_cv` (remember to set your seed)
      - Perform hyperparamter tuning with a random grid search using the `grid_random()` function
      - Refer to the following tutorial for an example - [Random Grid Search](https://gmubusinessanalytics.netlify.app/lesson-08-r-tutorial.html#Hyperparameter_Tuning14){target="_blank"}
      - Hyperparameter tuning can take a significant amount of computing time. Be careful not to set the `size` argument of `grid_random()` too large. I recommend `size` = 10 or smaller.
      - Select the best model with `select_best()` and finalize your workflow
- Evaluate model performance on the test set by plotting an ROC curve using `autoplot()` and calculating the area under the ROC curve on your test data


```{r}
#Set the random seed
set.seed(315)

telecom_split <- initial_split(telecom_df, prop = 0.75, 
                                strata = canceled_service)
telecom_split
# Generate a training data frame
telecom_training <- telecom_split %>% training()

# View results
telecom_training

# Generate a test data frame
telecom_test <- telecom_split %>% testing()

# View results
telecom_test


```

```{r}
telecom_recipe <- recipe(canceled_service ~ .,
                          data = telecom_training)
summary(telecom_recipe)

```

```{r}
#Normalize

telecom_recipe %>% 
  step_normalize(all_numeric(), -all_outcomes()) %>% 
  prep(training = telecom_training) %>% 
  bake(new_data = NULL)

```

```{r}
# Transforming Highly skewed Data (MONTHLY CHARGES)
#BEFORE REMOVING SKEWNESS
ggplot(data = telecom_training, mapping = aes(x = monthly_charges)) +
  geom_histogram(fill = '#006EA1', color = 'white', bins = 10) +
  labs(title = 'Distribution of Monthly Charges',
       x = 'Monthly Charges',
       y = 'Number of Customers')
# transforming MONTHLY CHARGESin the training data with the Yeo-Johnson transformation
telecom_recipe %>% 
  step_YeoJohnson(monthly_charges) %>% 
  prep(training = telecom_training) %>% 
  bake(new_data = NULL)

# pipe the results from above into ggplot
telecom_recipe %>% 
  step_YeoJohnson(monthly_charges) %>% 
  prep(training = telecom_training) %>% 
  bake(new_data = NULL)%>% 
  ggplot( mapping = aes(x = monthly_charges)) +
  geom_histogram(fill = '#006EA1', color = 'white', bins = 10) +
  labs(title = 'Distribution of Monthly Charges',
       x = 'Monthly Charges',
       y = 'Number of Customers')

```

```{r}
# Transforming Highly skewed Data (NO OF MONTHS WITH COMPANY)
#BEFORE REMOVING SKEWNESS
ggplot(data = telecom_training, mapping = aes(x = months_with_company)) +
  geom_histogram(fill = '#006EA1', color = 'white', bins = 10) +
  labs(title = 'Distribution of Months with the company',
       x = 'Months with the company',
       y = 'Number of Customers')
# transforming NO OF MONTHS WITH COMPANY in the training data with the Yeo-Johnson transformation
telecom_recipe %>% 
  step_YeoJohnson(months_with_company) %>% 
  prep(training = telecom_training) %>% 
  bake(new_data = NULL)

# pipe the results from above into ggplot
telecom_recipe %>% 
  step_YeoJohnson(months_with_company) %>% 
  prep(training = telecom_training) %>% 
  bake(new_data = NULL)%>% 
  ggplot( mapping = aes(x = months_with_company)) +
  geom_histogram(fill = '#006EA1', color = 'white', bins = 10) +
  labs(title = 'Distribution of Months with the company',
       x = 'Months with the company',
       y = 'Number of Customers')


```

```{r}
# Transforming Highly skewed Data (NAVG CALL DURATION IN MINUTES
#BEFORE REMOVING SKEWNESS
ggplot(data = telecom_training, mapping = aes(x = avg_call_mins)) +
  geom_histogram(fill = '#006EA1', color = 'white', bins = 10) +
  labs(title = 'Distribution of Average Call in Minutes',
       x = 'Months with the company',
       y = 'Number of Customers')
# transforming NO OF MONTHS WITH COMPANY in the training data with the Yeo-Johnson transformation
telecom_recipe %>% 
  step_YeoJohnson(avg_call_mins) %>% 
  prep(training = telecom_training) %>% 
  bake(new_data = NULL)

# pipe the results from above into ggplot
telecom_recipe %>% 
  step_YeoJohnson(avg_call_mins) %>% 
  prep(training = telecom_training) %>% 
  bake(new_data = NULL)%>% 
  ggplot( mapping = aes(x = avg_call_mins)) +
  geom_histogram(fill = '#006EA1', color = 'white', bins = 10) +
  labs(title = 'Distribution of Average Call in Minutes',
       x = 'Months with the company',
       y = 'Number of Customers')

```


```{r}
# Transforming Highly skewed Data (AVG INTL CALL DURATION IN MINUTES
#BEFORE REMOVING SKEWNESS
ggplot(data = telecom_training, mapping = aes(x = avg_intl_mins)) +
  geom_histogram(fill = '#006EA1', color = 'white', bins = 10) +
  labs(title = 'Distribution of Average International Call in Minutes',
       x = 'Months with the company',
       y = 'Number of Customers')
# transforming NO OF MONTHS WITH COMPANY in the training data with the Yeo-Johnson transformation
telecom_recipe %>% 
  step_YeoJohnson(avg_intl_mins) %>% 
  prep(training = telecom_training) %>% 
  bake(new_data = NULL)

# pipe the results from above into ggplot
telecom_recipe %>% 
  step_YeoJohnson(avg_intl_mins) %>% 
  prep(training = telecom_training) %>% 
  bake(new_data = NULL)%>% 
  ggplot( mapping = aes(x = avg_intl_mins)) +
  geom_histogram(fill = '#006EA1', color = 'white', bins = 10) +
  labs(title = 'Distribution of Average Call in Minutes',
       x = 'Months with the company',
       y = 'Number of Customers')

```


```{r}
# ALL TRANSFORMATIONS TOGETHER
telecom_numeric <- recipe(canceled_service ~ .,
                           data = telecom_training) %>% 
  step_corr(all_numeric(), -all_outcomes()) %>%  
  step_YeoJohnson(all_numeric(), -all_outcomes()) %>% 
  step_normalize(all_numeric(), -all_outcomes()) %>% 
  prep(training = telecom_training)

```


```{r}
# apply the transformations to our training and test data with bake()
processed_telecom_training <- telecom_numeric %>% 
  bake(new_data = NULL)

```

```{r}
processed_telecom_test <- telecom_numeric %>% 
  bake(new_data = telecom_test)

```

```{r}
# View results
processed_telecom_training

# View results
processed_telecom_test

```


```{r}
# PROCESSING THE CATEGORICAL VARIABLES

telecom_recipe %>% 
  step_dummy(senior_citizen,spouse_partner,dependents,
             cellular_service,internet_service,online_security,
             online_backup,device_protection,tech_support,streaming_tv,
             streaming_movies,contract,paperless_bill,payment_method) %>% 
  prep(training = telecom_training) %>% 
  bake(new_data = NULL)

```


```{r}
telecom_transformations <- recipe(canceled_service ~ .,
                                   data = telecom_training)  %>% 
  # Transformation steps
  step_YeoJohnson(all_numeric(), -all_outcomes()) %>%
  step_normalize(all_numeric(), -all_outcomes()) %>% 
  step_dummy(all_nominal(), -all_outcomes()) %>% 
  # Train transformations on employee_training
  prep(training = telecom_training)


```

```{r}
# Apply to telecom_test
telecom_transformations %>% 
  bake(new_data = telecom_test)

```


# Model 1

```{r}
#LOGISTIC REGRESSION
levels(telecom_df$canceled_service)

# Specify a logistic regression model
logistic_model <- logistic_reg() %>% 
  # Set the engine
  set_engine('glm') %>% 
  # Set the mode
  set_mode('classification')


```

```{r}
#CREATE THE WORKFLOW
telecom_wf <- workflow() %>% 
  add_model(logistic_model) %>% 
  add_recipe(telecom_transformations)

```

```{r}
# Fit to training data
telecom_logistic_fit <- telecom_wf %>% 
  fit(data = telecom_training)


telecom_trained_model <- telecom_logistic_fit %>% 
  pull_workflow_fit()

# VARIABLE IMPORTANCE
vip(telecom_trained_model)

```

```{r}
#PREDICTED CATEGORIES 
predictions_categories <- predict(telecom_logistic_fit, 
                                  new_data = telecom_test)

predictions_categories

```


```{r}
#PREDICTED CATEGORIES WITH PROB

predictions_probabilities <- predict(telecom_logistic_fit, 
                                     new_data = telecom_test, 
                                     type = 'prob')

predictions_probabilities

```


```{r}
# Combine

test_results <- telecom_test %>% select(canceled_service) %>% 
                bind_cols(predictions_categories) %>% 
                bind_cols(predictions_probabilities)

test_results
```


```{r}
#CONFUSION MATRIX
conf_mat(test_results, 
         truth = canceled_service, 
         estimate = .pred_class)

```



```{r}
#Specificity

spec(test_results,
     truth = canceled_service, 
     estimate = .pred_class)

```



```{r}
#ROC CURVE

roc_curve(test_results, 
          truth = canceled_service,
          estimate = .pred_yes)
roc_curve(test_results, 
          truth = canceled_service, 
          estimate = .pred_yes) %>% 
  autoplot()

roc_auc(test_results,
        truth = canceled_service, 
        .pred_yes)

```




# Model 2

```{r}
#LDA MODEL SPECIFICATION

lda_model <- discrim_regularized(frac_common_cov = 1) %>% 
  set_engine('klaR') %>% 
  set_mode('classification')


```

```{r}
#CREATING WORKFLOW

lda_wf <- workflow() %>% 
  add_model(lda_model) %>% 
  add_recipe(telecom_transformations)

```


```{r}
#Train and Evaluate With last_fit()
last_fit_lda <- lda_wf %>% 
  last_fit(split = telecom_split)

last_fit_lda %>% collect_metrics()

```


```{r}
lda_predictions <- last_fit_lda %>% 
  collect_predictions()

lda_predictions

```


```{r}

#ROC CURVE

roc_curve(lda_predictions, 
          truth = canceled_service,
          estimate = .pred_yes)
roc_curve(lda_predictions, 
          truth = canceled_service, 
          estimate = .pred_yes) %>% 
  autoplot()

roc_auc(lda_predictions,
        truth = canceled_service, 
        .pred_yes)


```



```{r}
#CONFUSION MATRIX
conf_mat(lda_predictions, truth = canceled_service, estimate = .pred_class)

```


```{r}
#Specificity

spec(lda_predictions,
     truth = canceled_service, 
     estimate = .pred_class)

```





# Model 3

```{r}
# KNN 
### Create folds for cross validation on the training data set
## These will be used to tune model hyperparameters
set.seed(315)

cancelled_service_folds <- vfold_cv(telecom_training, v = 5)


```


```{r}
#MODEL SPECIFICATION
knn_model <- nearest_neighbor(neighbors = tune()) %>% 
  set_engine('kknn') %>% 
  set_mode('classification')


```



```{r}
#Creating a Workflow
knn_wf <- workflow() %>% 
  add_model(knn_model) %>% 
  add_recipe(telecom_transformations)


```



```{r}
#Hyperparameter tuning
## Create a grid of hyperparameter values to test
k_grid <- tibble(neighbors = c(10, 20, 30, 50, 75, 100, 125, 150))

# View grid
k_grid


```



```{r}
## Tune  workflow
set.seed(315)

knn_tuning <- knn_wf %>% 
  tune_grid(resamples = cancelled_service_folds,
            grid = k_grid)

## Show the top 5 best models based on roc_auc metric
knn_tuning %>% show_best('roc_auc')

```



```{r}
## Select best model based on roc_auc
best_k <- knn_tuning %>% 
  select_best(metric = 'roc_auc')

## View model
best_k



```



```{r}
## Finalize workflow by adding the best performing model
final_knn_wf <- knn_wf %>% 
  finalize_workflow(best_k)

last_fit_knn <- final_knn_wf %>% 
  last_fit(split = telecom_split)


```




```{r}
knn_predictions <- last_fit_knn %>% 
  collect_predictions()

knn_predictions



```

```{r}

#ROC CURVE

roc_curve(knn_predictions, 
          truth = canceled_service,
          estimate = .pred_yes)
roc_curve(knn_predictions, 
          truth = canceled_service, 
          estimate = .pred_yes) %>% 
  autoplot()

roc_auc(knn_predictions,
        truth = canceled_service, 
        .pred_yes)


```

```{r}
conf_mat(knn_predictions, truth = canceled_service, estimate = .pred_class)


```

```{r}

#Specificity

spec(knn_predictions,
     truth = canceled_service, 
     estimate = .pred_class)

```


# Model 4


```{r}
#SPECIFY THE MODEL

rf_model <- rand_forest(mtry = tune(),
                        trees = tune(),
                        min_n = tune()) %>% 
  set_engine('ranger', importance = "impurity") %>% 
  set_mode('classification')

```


```{r}
#Workflow

rf_workflow <- workflow() %>% 
  add_model(rf_model) %>% 
  add_recipe(telecom_transformations)

```


```{r}
## Create a grid of hyperparameter values to test

set.seed(315)

rf_grid <- grid_random(mtry() %>% range_set(c(2, 4)),
                       trees(),
                       min_n(),
                       size = 10)

# View grid
rf_grid


```


```{r}
## Tune random forest workflow
set.seed(315)

rf_tuning <- rf_workflow %>% 
  tune_grid(resamples = cancelled_service_folds,
            grid = rf_grid)


## Show the top 5 best models based on roc_auc metric
rf_tuning %>% show_best('roc_auc')

```


```{r}
## Select best model based on roc_auc
best_rf <- rf_tuning %>% 
  select_best(metric = 'roc_auc')

# View the best parameters
best_rf


```


```{r}
#FINALIZE WORKFLOW
final_rf_workflow <- rf_workflow %>% 
  finalize_workflow(best_rf)

#FITTING THE MODEL FOR VARIABLE IMPORTANCE

rf_wf_fit <- final_rf_workflow %>% 
  fit(data = telecom_training)

```



```{r}
#extract the trained model from our workflow fit
rf_fit <- rf_wf_fit %>% 
  pull_workflow_fit()

#Variable Importance Plot
vip(rf_fit)


```



```{r}
#Train and Evaluate With last_fit()

rf_last_fit <- final_rf_workflow %>% 
  last_fit(telecom_split)

#performance metrics on the test data

rf_last_fit %>% collect_metrics()


```

```{r}

#ROC CURVE
rf_last_fit %>% collect_predictions() %>% 
  roc_curve(truth  = canceled_service, estimate = .pred_yes) %>% 
  autoplot()


```


```{r}
#Confusion Matrix

conf_mat(rf_predictions, truth = canceled_service, estimate = .pred_class)


```



```{r}
#Specificity

spec(rf_predictions,
     truth = canceled_service, 
     estimate = .pred_class)


```


# Summary of Results

Write a summary of your overall findings and recommendations to the executives at the company. Think of this section as your closing remarks of a presentation, where you summarize your key findings, model performance, and make recommendations to improve customer retention and service at this company.

Your executive summary must be written in a [professional tone](https://www.universalclass.com/articles/writing/business-writing/appropriate-tone-in-business-communications.htm), with minimal grammatical errors, and should include the following sections:

1. An introduction where you explain the business problem and goals of your data analysis

    - What problem(s) is this company trying to solve? Why are they important to their future success?
  
    - What was the goal of your analysis? What questions were you trying to answer and why do they matter?


2. Highlights and key findings from your Exploratory Data Analysis section 
    - What were the interesting findings from your analysis and **why are they important for the business**?

    - This section is meant to **establish the need for your recommendations** in the following section


3. Your “best” classification model and an analysis of its performance 
    - In this section you should talk about the expected error of your model on future data
      - To estimate future performance, you can use your model performance results on the **test data**
    - You should discuss at least one performance metric, such as an F1, sensitivity, specificity, or ROC AUC for your model. However, you must explain the results in an **intuitive, non-technical manner**. Your audience in this case are executives at a telecommunications company with limited knowledge of machine learning.


4. Your recommendations to the company on how to reduce customer attrition rates 
  
    - Each recommendation must be supported by your data analysis results 

    - You must clearly explain why you are making each recommendation and which results from your data analysis support this recommendation

    - You must also describe the potential business impact of your recommendation:
      
      - Why is this a good recommendation? 
      
      - What benefits will the business achieve?




**Summary**

Add your summary here. Please do not place your text within R code chunks.

For the Telecommunication Company, avoiding the customer churn or customer retention is as important as attracting the new costumers when the company wants to grow their generating revenue. There would be many key factors or reasons that trigger customers to terminate their service. A customer retention analysis is a typical classification problem within the domain of supervised learning. The main goal of the analysis is to analyze the factors which affect the customer termination and take the respective measures to reduce them. 

Here, we are analyzing on the factors such as Avg call duration in mins, contract, Avg international calls in mins, internet service online security, online backup, device protection, tech support, streaming tv, streaming movies, paperless bill, payment method, months with the company, monthly charges, Senior Citizen, spouse partner, dependents, cellular service. 

Customers who have terminated their service varies for different reasons and analytics provides valuable capabilities to predict customer churn and also define the underlying reasons that drive it. It is found that the most important factors that affect are Monthly charges, the type of contract, Online security, Internet Service, Average call duration in minutes, online backup, Average International call duration in minutes and months with the company. So, the telecom company should focus on these factors to minimize the retention rates. 

The primary reason the customers tend to leave the company is due to amount i.e., monthly charges they’ve been charged to the type of contract they have enrolled in. From the plot, it can be observed that though the customers who have enrolled in the same type of contact, those customers who left the company have paid more monthly charges than those who stayed back. 

Another key factor by which the customers are terminating the service is due to the online security provided by the company over the progress of years. This means that most of the customers who have cancelled their service doesn’t have the online security even though many years progressed and hence due to insecurity, most of the costumers have terminated the service.

The customer’s call duration in minutes also give information about the reason why the customers have terminated the service. From the plot, we can say that as the years progress, the average duration of call has been reduced gradually which means that the customers no longer are making calls and are not having communication through their cell which means that they no longer have to pay the charges and use the service which in turn is leading of customers to terminate the service.

Online backup is also one of the reasons for the customers churning of the service. Those customers who had their online backup of data paid the same amount of charge when compared to those who didn’t stop their service. This shows that the telecom company has bias wherein though they have opted for same services they have been charged differently for which the customers are cancelling the services. 

Also, those customers who left the company have paid the same amount of charges irrespective of having the international calls. From the analysis, though the customers who left the company have used less minutes of international call than those who haven’t left the company, both of the customers are being charged with the same amount which makes unfair and leading them to terminate the service.
Some of the interesting findings through the data analysis is that Senior citizens churn rate is much higher than non-senior churn rate. Also, from the data analysis, we could say that the rate of termination of the service is moderately high for those who are independent and for those customers who do not have partners. 

From the type of payment method, we can see that electronic check shows much higher churn rate than other payment methods. In addition, the Customers with Internet Service of fiber optic as part of their contract have much higher churn rate.

Those Customers who are terminating the service have much lower number of months associated with the company when compared to non-churners. Also, the greater number of months the customers are associated with the company, the less chance that the customers tending to terminate the services. 

Here, US Telecommunications company have applied Machine Learning models in order to predict the various factors leading to service retention. To achieve that, machine learning models are trained dependent on 75% of the sample data.  The other 25% are utilized to apply the trained models and survey their predictive power with respect to their cancelation of service. Machine Learning Models that are used to predict the reasons for customers cancelling their services are Logistic Regression, KNN, Random Forest and Linear Discriminant Analysis (LDA). The metrics which I’ve considered are Specificity and ROC AUC. 

From all the Machine Learning Models, it can be observed that Logistic Regression is the best Machine Learning model which has the AUC score of about 0.856 which means it could predict and classify 85% of the test data accurately and also it has specificity of 80% which says that it could correctly classify the number of non-churn customers. 

For Logistic Regression, the area under the curve i.e., ROC AUC is 0.856 which means that it comes under the grade of B and this area under the curve is one of the performance metrics that explains about the model performance. It also explains about the how much the model is capable of predicting the outcome variable. So, higher the AUC, the better the model in predicting. So, from the AUC value which we have obtained, it can be said that 85% of the values are correctly classified. The Specificity is something which is used to estimate the rate of correctly estimated non churn customers which means that it explains about those who do not stop the service and it about 0.801. 

For the Linear Discriminant Analysis, the area under the curve i.e., ROC AUC is about 0.856 which also comes under the B category and this model has the same performance as that of Logistic Regression. So, from the AUC value, we can say that LDA model also predicts 85% of the values correctly. But the specificity value varies, and it is about 0.791 for LDA. 

For Random Forest, we have used the grid parameter search by which we have predicted the optimized values for the parameter, and it is observed that the area under the curve i.e., ROC AUC is about 0.831 for which the model performs slightly less than that of LDA and Logistic Regression. From the AUC vales, we can say that the model predicts 83% of the values correctly which means that it would be able to predict the outcome variable i.e., those who have terminated the service. But, for Specificity the Random Forest model performs better which is about 0.807.

For the KNN clustering, the area under the curve i.e., AUC ROC is about 0.840 which also comes under the B category and this model has the same performance as that of Logistic Regression. So, this KNN model can predict 84% of the values correctly. But the specificity value varies, and it is about 0.781 for LDA.

One of the most important recommendations to reduce service retention rates is to bill the monthly charges according to their use. For example, charging less monthly charge when they make less number of calls rather than a constant amount to be charged irrespective of usage of services.
Benefit: This helps the customers keep encouraged and will be associated with the company for longer tenure.

Another main recommendation can be to providing the online security for their internet as well as cellular services. 
Benefit: By providing the online security for the cellular services as well as for internet services, it would help customer’s system protect from the anti-virus which helps in keeping up their customers and also represent potentially large additional revenue source if it is done in the early phase.

Another Recommendation is taking the measures such as providing the discounts, special offers or any other gratifications and mass advertising to increase brand loyalty and thus retain customers.
Benefit: It helps the organizations in attracting the customers which in turn in adds up to enrolment of new customers as well as retain their previous customers.

Lastly, having bias-free and charging appropriate amount depending upon the contract either monthly or yearly. 
Benefit: Having such a bias-free environment, which means charging the same amount for their respective contract without any partiality would lead to customers staying back with the company and they could use the services which in turn helps in generating the revenue for the company.  




















